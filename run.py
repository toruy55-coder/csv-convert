#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVçµåˆãƒ»å¤‰æ›ãƒ„ãƒ¼ãƒ« - Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆç‰ˆ
ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸè¨­å®šã‚’ä½¿ç”¨ã—ã¦ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆãƒ»å¤‰æ›ã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    python run.py [è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å]

    ä¾‹: python run.py settings.json
        python run.py ãƒ†ã‚¹ãƒˆè¨­å®š01.json
"""

import csv
import json
import os
import sys
from datetime import datetime
from collections import defaultdict


def ensure_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è‡ªå‹•ä½œæˆ"""
    os.makedirs('input', exist_ok=True)
    os.makedirs('output', exist_ok=True)


def load_config(config_path=None):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    # å¼•æ•°ã§æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¢ã™
    if config_path is None:
        # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® .json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        json_files = [f for f in os.listdir('.') if f.endswith('.json')]

        if not json_files:
            print("âŒ ã‚¨ãƒ©ãƒ¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print()
            print("ä½¿ã„æ–¹:")
            print("  python run.py [è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å]")
            print()
            print("ä¾‹:")
            print("  python run.py settings.json")
            print("  python run.py ãƒ†ã‚¹ãƒˆè¨­å®š01.json")
            print()
            print("ã¾ãŸã¯ã€ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« .json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)

        if len(json_files) == 1:
            config_path = json_files[0]
            print(f"ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡º: {config_path}")
        else:
            print("âŒ ã‚¨ãƒ©ãƒ¼: è¤‡æ•°ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            print()
            print("ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰1ã¤ã‚’é¸ã‚“ã§æŒ‡å®šã—ã¦ãã ã•ã„:")
            for f in json_files:
                print(f"  - {f}")
            print()
            print("ä½¿ã„æ–¹: python run.py [è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å]")
            sys.exit(1)

    if not os.path.exists(config_path):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        print()
        print("ãƒ–ãƒ©ã‚¦ã‚¶ã§è¨­å®šã‚’ä½œæˆã—ã€JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {config['name']}")
        return config
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


def find_input_file(file_name):
    """å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™ï¼ˆã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª â†’ input/ ã®é †ï¼‰"""
    # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å„ªå…ˆ
    if os.path.exists(file_name):
        return file_name

    # input/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    input_path = os.path.join('input', file_name)
    if os.path.exists(input_path):
        return input_path

    return None


def load_csv(file_name):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    file_path = find_input_file(file_name)

    if file_path is None:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
        print(f"   ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¾ãŸã¯ input/ ãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            data = list(reader)
        print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {file_path} ({len(data)-1}è¡Œ)")
        return data
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


def validate_data(data_a, data_b, config):
    """ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
    warnings = []
    validation = config.get('validation', {})
    key_a = int(config['keyA'])
    key_b = int(config['keyB'])

    # ç©ºç™½ã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
    if validation.get('checkBlank', False):
        blank_count_a = sum(1 for row in data_a[1:] if not row[key_a].strip())
        blank_count_b = sum(1 for row in data_b[1:] if not row[key_b].strip())

        if blank_count_a > 0:
            warnings.append(f"CSV Aã®çµåˆã‚­ãƒ¼ã«ç©ºç™½ãŒ{blank_count_a}ä»¶ã‚ã‚Šã¾ã™")
        if blank_count_b > 0:
            warnings.append(f"CSV Bã®çµåˆã‚­ãƒ¼ã«ç©ºç™½ãŒ{blank_count_b}ä»¶ã‚ã‚Šã¾ã™")

    # é‡è¤‡ã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
    if validation.get('checkDuplicate', False):
        keys_a = [row[key_a] for row in data_a[1:]]
        keys_b = [row[key_b] for row in data_b[1:]]

        dup_count_a = len(keys_a) - len(set(keys_a))
        dup_count_b = len(keys_b) - len(set(keys_b))

        if dup_count_a > 0:
            warnings.append(f"CSV Aã®çµåˆã‚­ãƒ¼ã«é‡è¤‡ãŒ{dup_count_a}ä»¶ã‚ã‚Šã¾ã™")
        if dup_count_b > 0:
            warnings.append(f"CSV Bã®çµåˆã‚­ãƒ¼ã«é‡è¤‡ãŒ{dup_count_b}ä»¶ã‚ã‚Šã¾ã™")

    # ã‚«ãƒ©ãƒ æ•°ä¸ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if validation.get('checkColumnCount', False):
        col_count_a = len(data_a[0])
        col_count_b = len(data_b[0])

        mismatch_a = sum(1 for row in data_a[1:] if len(row) != col_count_a)
        mismatch_b = sum(1 for row in data_b[1:] if len(row) != col_count_b)

        if mismatch_a > 0:
            warnings.append(f"CSV Aã«ã‚«ãƒ©ãƒ æ•°ä¸ä¸€è‡´ã®è¡ŒãŒ{mismatch_a}ä»¶ã‚ã‚Šã¾ã™")
        if mismatch_b > 0:
            warnings.append(f"CSV Bã«ã‚«ãƒ©ãƒ æ•°ä¸ä¸€è‡´ã®è¡ŒãŒ{mismatch_b}ä»¶ã‚ã‚Šã¾ã™")

    if warnings:
        print("âš ï¸  è­¦å‘Š:")
        for warning in warnings:
            print(f"   - {warning}")

    return warnings


def perform_join(data_a, data_b, config):
    """CSVçµåˆã‚’å®Ÿè¡Œ"""
    key_a = int(config['keyA'])
    key_b = int(config['keyB'])
    join_type = config['joinType']
    columns = config['columns']

    # Bå´ã‚’ãƒãƒƒãƒ—ã«å¤‰æ›
    map_b = defaultdict(list)
    for row in data_b[1:]:
        if key_b < len(row):
            key = row[key_b]
            map_b[key].append(row)

    result = []
    matched_keys_b = set()

    # å‡ºåŠ›ãƒ˜ãƒƒãƒ€ãƒ¼
    output_headers = [col['name'] for col in columns if col.get('selected', True)]
    result.append(output_headers)

    # Inner/Left/Outer Join
    if join_type in ['inner', 'left', 'outer']:
        for row_a in data_a[1:]:
            if key_a >= len(row_a):
                continue

            key = row_a[key_a]
            rows_b = map_b.get(key, [])

            if rows_b:
                for row_b in rows_b:
                    output_row = []
                    for col in columns:
                        if not col.get('selected', True):
                            continue

                        if col['source'] == 'A':
                            idx = col['index']
                            output_row.append(row_a[idx] if idx < len(row_a) else '')
                        else:
                            idx = col['index']
                            output_row.append(row_b[idx] if idx < len(row_b) else '')

                    result.append(output_row)
                matched_keys_b.add(key)
            elif join_type in ['left', 'outer']:
                output_row = []
                for col in columns:
                    if not col.get('selected', True):
                        continue

                    if col['source'] == 'A':
                        idx = col['index']
                        output_row.append(row_a[idx] if idx < len(row_a) else '')
                    else:
                        output_row.append('')

                result.append(output_row)

    # Right Join
    if join_type == 'right':
        # Aå´ã‚’ãƒãƒƒãƒ—ã«å¤‰æ›
        map_a = defaultdict(list)
        for row in data_a[1:]:
            if key_a < len(row):
                key = row[key_a]
                map_a[key].append(row)

        for row_b in data_b[1:]:
            if key_b >= len(row_b):
                continue

            key = row_b[key_b]
            rows_a = map_a.get(key, [])

            if rows_a:
                for row_a in rows_a:
                    output_row = []
                    for col in columns:
                        if not col.get('selected', True):
                            continue

                        if col['source'] == 'A':
                            idx = col['index']
                            output_row.append(row_a[idx] if idx < len(row_a) else '')
                        else:
                            idx = col['index']
                            output_row.append(row_b[idx] if idx < len(row_b) else '')

                    result.append(output_row)
            else:
                output_row = []
                for col in columns:
                    if not col.get('selected', True):
                        continue

                    if col['source'] == 'B':
                        idx = col['index']
                        output_row.append(row_b[idx] if idx < len(row_b) else '')
                    else:
                        output_row.append('')

                result.append(output_row)

    # Outer Join: Bå´ã®æœªãƒãƒƒãƒè¡Œã‚’è¿½åŠ 
    if join_type == 'outer':
        for row_b in data_b[1:]:
            if key_b >= len(row_b):
                continue

            key = row_b[key_b]
            if key in matched_keys_b:
                continue

            output_row = []
            for col in columns:
                if not col.get('selected', True):
                    continue

                if col['source'] == 'B':
                    idx = col['index']
                    output_row.append(row_b[idx] if idx < len(row_b) else '')
                else:
                    output_row.append('')

            result.append(output_row)

    print(f"âœ… çµåˆå®Œäº†: {len(result)-1}è¡Œå‡ºåŠ›")
    return result


def apply_conversion_rules(data, rules):
    """å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨"""
    if not rules:
        return data

    headers = data[0]
    column_indices = {header: idx for idx, header in enumerate(headers)}

    converted_count = 0
    for rule in rules:
        if not rule.get('column') or not rule.get('from'):
            continue

        col_idx = column_indices.get(rule['column'])
        if col_idx is None:
            continue

        for row in data[1:]:
            if col_idx < len(row) and row[col_idx] == rule['from']:
                row[col_idx] = rule['to']
                converted_count += 1

    if converted_count > 0:
        print(f"âœ… å¤‰æ›ãƒ«ãƒ¼ãƒ«é©ç”¨: {converted_count}ä»¶å¤‰æ›")

    return data


def remove_duplicates(data):
    """é‡è¤‡è¡Œã‚’é™¤å»"""
    seen = set()
    unique = [data[0]]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã¯æ®‹ã™

    for row in data[1:]:
        key = '|'.join(row)
        if key not in seen:
            seen.add(key)
            unique.append(row)

    removed_count = len(data) - len(unique)
    if removed_count > 0:
        print(f"âœ… é‡è¤‡è¡Œé™¤å»: {removed_count}è¡Œé™¤å»")

    return unique, removed_count


def save_csv(data, output_path):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ï¼ˆBOMä»˜ãUTF-8ï¼‰"""
    try:
        # output ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        os.makedirs('output', exist_ok=True)

        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(data)
        print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        return True
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False


def save_log(config_name, file_a, file_b, output_rows, warnings, removed_count, output_file):
    """å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜"""
    # output ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs('output', exist_ok=True)

    log_path = 'output/run_log.csv'

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
    if not os.path.exists(log_path):
        with open(log_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['å®Ÿè¡Œæ—¥æ™‚', 'è¨­å®šå', 'ãƒ•ã‚¡ã‚¤ãƒ«A', 'ãƒ•ã‚¡ã‚¤ãƒ«B', 'å‡ºåŠ›è¡Œæ•°', 'è­¦å‘Šæœ‰ç„¡', 'é‡è¤‡é™¤å»', 'å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«'])

    # ãƒ­ã‚°ã‚’è¿½è¨˜
    try:
        with open(log_path, 'a', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                config_name,
                file_a,
                file_b,
                output_rows,
                'ã‚ã‚Š' if warnings else 'ãªã—',
                f'{removed_count}è¡Œ' if removed_count > 0 else 'ãªã—',
                output_file
            ])
        print(f"âœ… å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {log_path}")
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Š: å®Ÿè¡Œãƒ­ã‚°ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("CSVçµåˆãƒ»å¤‰æ›ãƒ„ãƒ¼ãƒ« - Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆç‰ˆ")
    print("=" * 60)
    print()

    # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    ensure_directories()

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    config_path = sys.argv[1] if len(sys.argv) > 1 else None

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    config = load_config(config_path)

    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
    file_a_name = config.get('fileNameA', 'input_a.csv')
    file_b_name = config.get('fileNameB', 'input_b.csv')

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    print("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    data_a = load_csv(file_a_name)
    data_b = load_csv(file_b_name)
    print()

    # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ä¸­...")
    warnings = validate_data(data_a, data_b, config)
    print()

    # çµåˆå®Ÿè¡Œ
    print("ğŸ”„ CSVçµåˆã‚’å®Ÿè¡Œä¸­...")
    result = perform_join(data_a, data_b, config)
    print()

    # å¤‰æ›ãƒ«ãƒ¼ãƒ«é©ç”¨
    if config.get('rules'):
        print("ğŸ”§ å¤‰æ›ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨ä¸­...")
        result = apply_conversion_rules(result, config['rules'])
        print()

    # é‡è¤‡è¡Œé™¤å»
    removed_count = 0
    if config.get('validation', {}).get('removeDuplicates', False):
        print("ğŸ—‘ï¸  é‡è¤‡è¡Œã‚’é™¤å»ä¸­...")
        result, removed_count = remove_duplicates(result)
        print()

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    output_base = config.get('name', 'output').replace(' ', '_')
    output_file = f"{output_base}_{timestamp}.csv"
    output_path = os.path.join('output', output_file)

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    print("ğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ä¸­...")
    if save_csv(result, output_path):
        print()

        # å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜
        print("ğŸ“ å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜ä¸­...")
        save_log(
            config['name'],
            file_a_name,
            file_b_name,
            len(result) - 1,
            warnings,
            removed_count,
            output_file
        )
        print()

        # çµæœã‚µãƒãƒªãƒ¼
        print("=" * 60)
        print("âœ¨ å‡¦ç†å®Œäº†")
        print("=" * 60)
        print(f"ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
        print(f"ğŸ“Š å‡ºåŠ›è¡Œæ•°: {len(result)-1}è¡Œ")
        print(f"ğŸ“Š å‡ºåŠ›ã‚«ãƒ©ãƒ æ•°: {len(result[0])}åˆ—")
        if removed_count > 0:
            print(f"ğŸ—‘ï¸  é‡è¤‡é™¤å»: {removed_count}è¡Œ")
        if warnings:
            print(f"âš ï¸  è­¦å‘Š: {len(warnings)}ä»¶")
        print("=" * 60)

        return 0
    else:
        return 1


if __name__ == '__main__':
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
